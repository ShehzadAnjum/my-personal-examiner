# Feature Specification: Resource Bank - Centralized Content Repository

**Feature Branch**: `006-resource-bank`
**Created**: 2025-12-25
**Status**: Draft
**Input**: User description: "Centralized resource management system with DB-primary storage, local file caching, signature-based sync, versioned content (v1 admin, v2+ student with own API keys), and individual learning path tracking."

## Overview

A centralized resource management system that stores all generated educational content (topic explanations, questions, external resources) in a shared database, with local file-based caching and signature-based synchronization. Resources are shared across all students to maximize token efficiency, while individual learning paths are tracked per student.

### Core Architecture Principles

1. **Two-Tier Storage**: Database is source of truth; local file cache for performance
2. **Shared Resources**: Generated content is created once and shared by all students
3. **Version Control**: Admin creates baseline (v1); students create personalized versions (v2+) using their own LLM keys
4. **Individual Learning Paths**: Each student's progress, preferences, and bookmarks are tracked separately
5. **Token Cost Protection**: v1 uses system resources; v2+ requires student's own API keys

## User Scenarios & Testing *(mandatory)*

### User Story 1 - View Shared Topic Explanation (Priority: P1)

As a student, I want to view a topic explanation that has already been generated by the admin, so that I can learn the concept without waiting for generation or consuming tokens.

**Why this priority**: This is the core value proposition - students get instant access to quality content without token costs. It's the foundation for all other features.

**Independent Test**: Can be fully tested by navigating to a topic that has a v1 explanation and verifying it loads instantly from the database/cache.

**Acceptance Scenarios**:

1. **Given** an admin has generated a v1 explanation for topic "Price Elasticity of Demand", **When** a student navigates to that topic, **Then** the explanation loads within 2 seconds without any LLM generation
2. **Given** a topic has no generated explanation yet, **When** a student navigates to that topic, **Then** they see a message indicating the topic is pending admin generation
3. **Given** a topic explanation exists in the database but not in local cache, **When** a student requests it, **Then** it is fetched from database and cached locally for future requests

---

### User Story 2 - Admin Generates Baseline Content (Priority: P1)

As an admin/teacher, I want to generate baseline (v1) explanations for syllabus topics using the system's LLM resources, so that all students have access to quality content.

**Why this priority**: Without v1 content, students have nothing to view. This is the content creation engine that populates the resource bank.

**Independent Test**: Can be fully tested by admin logging in, selecting a topic, generating an explanation, and verifying it appears for all students.

**Acceptance Scenarios**:

1. **Given** I am logged in as an admin, **When** I select a topic without a v1 explanation and click "Generate", **Then** the system uses system LLM credentials to create and save the explanation
2. **Given** a topic already has a v1 explanation, **When** I try to generate again, **Then** I am asked to confirm regeneration which will create a new version
3. **Given** I generate an explanation, **When** any student views that topic, **Then** they see my generated explanation immediately

---

### User Story 3 - Student Configures Personal LLM Keys (Priority: P2)

As a student, I want to configure my own LLM API keys in my settings, so that I can generate personalized explanation versions without using the system's resources.

**Why this priority**: Enables the v2+ personalization feature while protecting the system from token abuse.

**Independent Test**: Can be fully tested by a student adding their API key, verifying it's encrypted and saved, and confirming it's not exposed in responses.

**Acceptance Scenarios**:

1. **Given** I am logged in as a student, **When** I navigate to Settings > LLM Configuration, **Then** I see input fields for OpenAI, Anthropic, and Google API keys
2. **Given** I enter a valid API key, **When** I save it, **Then** the key is encrypted and stored, and only a masked version (last 4 characters) is displayed
3. **Given** I have saved an API key, **When** I view my settings later, **Then** I never see the full key, only confirmation it exists
4. **Given** I want to remove my API key, **When** I delete it, **Then** it is permanently removed and I can no longer generate personalized versions

---

### User Story 4 - Student Generates Personalized Version (Priority: P2)

As a student with configured API keys, I want to generate a personalized version of an explanation in my preferred style (Simpler, More Detailed, More Examples, Exam-Focused, or Visual/Diagram-Heavy), so that I can learn in a way that suits me best.

**Why this priority**: Enables personalization which improves learning outcomes, while ensuring cost is borne by the student.

**Independent Test**: Can be fully tested by a student with API keys requesting a "simpler" version and verifying it uses their key and creates a v2 entry.

**Acceptance Scenarios**:

1. **Given** I have configured my API key and am viewing a v1 explanation, **When** I click "Generate Simpler Version", **Then** the system uses MY API key to generate a v2 explanation linked to my account
2. **Given** I don't have an API key configured, **When** I try to generate a personalized version, **Then** I see a prompt to configure my API key first
3. **Given** I have multiple personalized versions, **When** I view the topic, **Then** I can switch between my versions and the official v1

---

### User Story 5 - Track Learning Progress (Priority: P2)

As a student, I want the system to automatically track which topics I've viewed, how long I spent, and my mastery level, so that I can see my learning progress.

**Why this priority**: Learning path tracking enables adaptive learning and personalized recommendations in future iterations.

**Independent Test**: Can be fully tested by viewing a topic, checking that view count increments, and verifying time spent is recorded.

**Acceptance Scenarios**:

1. **Given** I view a topic explanation, **When** the page loads, **Then** my view count for that topic increments and timestamp is recorded
2. **Given** I spend 5 minutes reading an explanation, **When** I navigate away, **Then** the time spent is added to my total for that topic
3. **Given** I have viewed multiple topics, **When** I visit my learning dashboard, **Then** I see my progress including topics viewed, time spent, and mastery indicators

---

### User Story 6 - Sync Cache with Database (Priority: P3)

As a system administrator, I want the local file cache to automatically sync with the database when changes occur, so that all instances serve consistent content.

**Why this priority**: Ensures data consistency but is not user-facing; can use stale cache with eventual consistency.

**Independent Test**: Can be fully tested by modifying a record in the database, triggering sync, and verifying the local cache updates.

**Acceptance Scenarios**:

1. **Given** a v1 explanation is updated in the database, **When** the sync runs, **Then** the local cache signature mismatches and content is refreshed
2. **Given** the local cache has content with matching signatures, **When** sync runs, **Then** no data is transferred (bandwidth efficient)
3. **Given** a new explanation is added to the database, **When** a student requests it and it's not in cache, **Then** it's fetched from database and added to cache

---

### User Story 7 - Bookmark Favorite Topics (Priority: P3)

As a student, I want to bookmark my favorite topics from the shared pool, so that I can quickly access them later for revision.

**Why this priority**: Convenience feature that enhances usability but is not core functionality.

**Independent Test**: Can be fully tested by bookmarking a topic and verifying it appears in the student's saved list.

**Acceptance Scenarios**:

1. **Given** I am viewing an explanation, **When** I click "Bookmark", **Then** the topic is added to my personal bookmarks list
2. **Given** I have bookmarked topics, **When** I visit "My Bookmarks", **Then** I see only my bookmarks (not other students')
3. **Given** I bookmarked a topic, **When** I click "Remove Bookmark", **Then** it no longer appears in my bookmarks

---

### Edge Cases

- What happens when a student's API key is invalid or expired? → Show clear error message and prompt to update key
- What happens when the database is unreachable? → Fall back to local cache with stale data warning
- What happens when local cache is corrupted? → Clear cache and re-fetch from database
- What happens when a student tries to access another student's personalized version? → Access denied with 403 error
- What happens when an admin tries to regenerate v1 while students have v2 versions? → v2 versions are preserved; only v1 is replaced
- How is LLM usage tracked for students? → Monthly token count stored and displayed in settings

## Requirements *(mandatory)*

### Functional Requirements

**Content Storage & Retrieval**
- **FR-001**: System MUST store all generated explanations in a centralized database as the source of truth
- **FR-002**: System MUST cache explanations in local file storage for performance optimization
- **FR-003**: System MUST serve cached content when available and signatures match
- **FR-004**: System MUST fall back to database when cache misses occur

**Version Control**
- **FR-005**: System MUST support version 1 (v1) explanations generated by admin using system LLM credentials
- **FR-006**: System MUST support version 2+ (v2, v3, ...) explanations generated by students using their own LLM API keys
- **FR-006a**: System MUST support 5 personalization styles: Simpler (reduced complexity, basic vocabulary), More Detailed (deeper explanations, additional context), More Examples (3x examples), Exam-Focused (mark scheme alignment, examiner tips), Visual/Diagram-Heavy (additional diagrams, visual representations)
- **FR-006b**: System MUST use distinct LLM prompts per style ensuring meaningful content differences (not superficial rewording)
- **FR-007**: System MUST prevent students from generating personalized versions without configured API keys
- **FR-008**: System MUST allow students to switch between v1 and their personalized versions

**Synchronization**
- **FR-009**: System MUST use signature-based change detection (hash of content + timestamp) for sync
- **FR-010**: System MUST sync from database to local cache (database is authoritative)
- **FR-011**: System MUST support sync triggers: on-demand, periodic (configurable interval), on startup
- **FR-012**: System MUST resolve conflicts by preferring database version

**Learning Path Tracking**
- **FR-013**: System MUST track per-student: topics viewed, view count, timestamps, time spent
- **FR-014**: System MUST track which explanation version each student prefers
- **FR-015**: System MUST track per-student bookmarks (favorites)
- **FR-016**: System MUST support mastery levels: not started, learning, familiar, mastered
- **FR-016a**: System MUST auto-progress mastery based on: views (3+ → familiar), time spent (10+ min → familiar), and short evaluation test results
- **FR-016b**: System MUST allow students to manually override their mastery level

**Student LLM Configuration**
- **FR-017**: System MUST allow students to configure API keys for OpenAI, Anthropic, and Google
- **FR-018**: System MUST encrypt student API keys at rest
- **FR-019**: System MUST never expose full API keys in responses or logs
- **FR-020**: System MUST track monthly token usage per student

**Security & Multi-tenancy**
- **FR-021**: System MUST enforce multi-tenant isolation on learning paths (students see only their own data)
- **FR-022**: System MUST prevent students from accessing other students' personalized versions
- **FR-023**: System MUST restrict v1 generation to admin role only (students with `is_admin=true`)
- **FR-024**: System MUST rate limit generation requests (10 per student per hour) with monitoring and alerts for abuse detection

### Key Entities

- **GeneratedExplanation**: Shared resource containing explanation content, version number, generator info (system or student), LLM provider used, token cost, quality rating, signature for sync
- **StudentLearningPath**: Per-student record linking to syllabus points, tracking views, time spent, preferred version, bookmarks, mastery level
- **StudentLLMConfig**: Encrypted storage of student's API keys by provider, with usage tracking
- **ResourceCache**: Metadata for local cache entries including file paths, signatures, and sync timestamps

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: Students can view admin-generated explanations within 2 seconds (cache hit scenario)
- **SC-002**: System achieves 90%+ cache hit rate after initial population
- **SC-003**: Zero duplicate LLM generations for the same v1 content (token savings)
- **SC-004**: 100% of student API keys are encrypted and never exposed in plaintext
- **SC-005**: Students can configure API keys and generate personalized versions in under 3 minutes
- **SC-006**: Learning path data is correctly tracked for 99%+ of topic views
- **SC-007**: Sync completes within 30 seconds for up to 1000 changed records
- **SC-008**: Multi-tenant isolation verified: students cannot access other students' data
- **SC-009**: Admin can generate v1 explanations for all syllabus topics (50+ topics)
- **SC-010**: Students report improved learning experience due to personalization (qualitative)

## Assumptions

1. Admin will generate v1 content for priority topics before student access
2. Students who want personalization will obtain their own LLM API keys
3. Local file cache storage has sufficient disk space for all cached content
4. Network latency between cache and database is acceptable for sync operations
5. LLM providers (OpenAI, Anthropic, Google) APIs remain stable and compatible
6. Standard AES-256 encryption is sufficient for API key storage

## Dependencies

- Existing SyllabusPoint data model for linking explanations to topics
- Existing Student authentication system for user identification
- Existing teaching page UI for displaying explanations
- LLM integration layer for calling OpenAI/Anthropic/Google APIs

## Clarifications

### Session 2025-12-25

- Q: How is admin role identified? → A: Flag on Student model (`is_admin` boolean)
- Q: What rate limits for generation? → A: 10 generations per student per hour + monitoring and alerts
- Q: How do mastery levels progress? → A: Auto-progress based on views/time + short evaluation test after each topic, manual override allowed
- Q: What personalization styles are supported? → A: Five styles (Simpler, More Detailed, More Examples, Exam-Focused, Visual/Diagram-Heavy) with distinct LLM prompts ensuring meaningful content differences

## Out of Scope

- Complex mastery algorithms based on exam performance (basic auto-progress via views/time/evaluation IS in scope)
- AI-powered recommendations based on learning path (future enhancement)
- Bulk import/export of explanations
- Version promotion workflow (student v2 → shared v1) - future feature
- Real-time collaborative editing of explanations
